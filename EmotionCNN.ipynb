{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0302a821-56c3-409e-bc52-8a8e9b4e58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "110f2a6b-df86-48f5-a996-1a2731bee259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './fer2013/train'\n",
    "test_dir = './fer2013/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37014a14-7232-4cd5-ae5b-e0c64f7f1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirpath,dirname,filenames in os.walk('/kaggle/input/fer2013'):\n",
    "    print(f'There are {len(dirname)} directories and {len(filenames)} images in {dirpath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6850a82f-b89e-473a-b71f-067e46689209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 47.5, 47.5, -0.5)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at some images\n",
    "from matplotlib.pyplot import imread\n",
    "img = imread('./fer2013/train/angry/Training_10118481.jpg')\n",
    "plt.imshow(img,'binary')\n",
    "plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a4df5ac6-6c35-4c9f-af3c-7e40c25ef28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load the data and scale it\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(directory='./fer2013/train',class_mode='binary')\n",
    "test_data = test_datagen.flow_from_directory(directory='./fer2013/test',class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb2d70dc-5651-4512-91eb-9572a82caf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=train_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0607b8c9-862f-465f-babf-8a22962af6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X>1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b02207c-1f8d-40c6-8d1d-b3d82db38bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D,Flatten,Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465088d9-470f-45bf-bd4f-cbf25a480da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#con 0.003 de Lr , 10 epochs un 45% de aceirto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7842c2af-7a45-411e-b136-26e768eef1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential([\n",
    "    Conv2D(15,3,activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(3,3)),\n",
    "    Conv2D(15,3,activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(3,3)),\n",
    "    Conv2D(15,3,activation='relu',padding='same'),\n",
    "    MaxPool2D(pool_size=(3,3)),\n",
    "    Flatten(),\n",
    "    Dense(7,activation='softmax')\n",
    "])\n",
    "model_3.compile(optimizer=Adam(0.003), # increasing learning rate as we are going for 5 epochs only(computational power constraint)\n",
    "               loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bd5b52f4-ab1e-40e3-a0c7-46eda3ff9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "898/898 [==============================] - ETA: 0s - loss: 1.6418 - accuracy: 0.3571\n",
      "Epoch 1: val_accuracy improved from -inf to 0.41321, saving model to best_model.h5\n",
      "898/898 [==============================] - 418s 465ms/step - loss: 1.6418 - accuracy: 0.3571 - val_loss: 1.5227 - val_accuracy: 0.4132 - lr: 0.0010\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlos/.local/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898/898 [==============================] - ETA: 0s - loss: 1.4825 - accuracy: 0.4328\n",
      "Epoch 2: val_accuracy improved from 0.41321 to 0.44121, saving model to best_model.h5\n",
      "898/898 [==============================] - 427s 476ms/step - loss: 1.4825 - accuracy: 0.4328 - val_loss: 1.4641 - val_accuracy: 0.4412 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "history_3=model_3.fit(train_data,epochs=2,\n",
    "                      steps_per_epoch=len(train_data),\n",
    "                      validation_data=test_data,\n",
    "                      validation_steps=len(test_data),\n",
    "                      callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c91664c1-1167-4437-9413-d13c691a485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_prediction(prediction):\n",
    "    # Asumiendo que 'prediction' es una matriz de probabilidades para cada clase\n",
    "    class_indices = ['Feliz', 'Triste', 'Enojado', 'Sorprendido', 'Neutral', 'Miedo', 'Disgustado']  # Actualiza según tus clases\n",
    "\n",
    "    # Obtener el índice de la clase con la mayor probabilidad\n",
    "    class_index = np.argmax(prediction)\n",
    "\n",
    "    # Devolver la etiqueta correspondiente\n",
    "    return class_indices[class_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f2dfb12-bf66-4fbd-9662-7735f3923847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 299, 299, 1)]     0         \n",
      "                                                                 \n",
      " rescaling_12 (Rescaling)    (None, 299, 299, 1)       0         \n",
      "                                                                 \n",
      " lambda_4 (Lambda)           (None, 299, 299, None)    0         \n",
      "                                                                 \n",
      " efficientnetb0 (Functional  (None, None, None, 1280   4049571   \n",
      " )                           )                                   \n",
      "                                                                 \n",
      " global_average_pooling2d_4  (None, 1280)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              1311744   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 7)                 7175      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5368490 (20.48 MB)\n",
      "Trainable params: 5326467 (20.32 MB)\n",
      "Non-trainable params: 42023 (164.16 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Lambda, Rescaling\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Asumiendo img_size = (altura, anchura) y num_classes = 7\n",
    "input_shape = img_size + (1,)\n",
    "num_classes = 7  # Actualizar con el número de clases real\n",
    "\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "# Escalar los valores de píxeles al rango que EfficientNet espera\n",
    "x = Rescaling(scale=1./255)(input_layer)\n",
    "\n",
    "# Expandir la imagen a 3 canales utilizando tf.cond\n",
    "def expand_channels(image):\n",
    "    return tf.cond(tf.shape(image)[-1] == 3, lambda: image, lambda: tf.repeat(image, 3, axis=-1))\n",
    "\n",
    "x = Lambda(expand_channels)(x)\n",
    "\n",
    "# Cargar EfficientNetB0 sin los pesos preentrenados y sin la parte superior\n",
    "efficientnet = EfficientNetB0(include_top=False, input_shape=(None, None, 3), weights=None)\n",
    "\n",
    "# Pasar la entrada a través de EfficientNet\n",
    "x = efficientnet(x)\n",
    "\n",
    "# Agregar capas de clasificación personalizadas\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Finalizar el modelo\n",
    "final_model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Compilar el modelo\n",
    "final_model.compile(optimizer=Adam(0.003), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Ver el resumen del modelo\n",
    "final_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ccb50a4-7a40-4d25-a5c8-b2e1ab7cd29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "opt=Adam(learning_rate=0.001)\n",
    "final_model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=opt,\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e50fb533-2d64-489e-b993-70f145654555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  7/898 [..............................] - ETA: 1:40:39 - loss: 2.1824 - accuracy: 0.2723"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      8\u001b[0m batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[0;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "checkpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "epochs=20\n",
    "batch_size=32\n",
    "\n",
    "history = final_model.fit(train_data,\n",
    "                          epochs=20,\n",
    "                          verbose=1,\n",
    "                          validation_data=test_data,\n",
    "                          callbacks=[reduce_lr, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f6578-6ad4-491a-a6b9-fecce05213d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
